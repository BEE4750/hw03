---
title: "BEE 4750 Homework 3: Uncertain Sea-Level Rise and Levee Reliability"
format:
    html:        
        warning: true
        error: true
    ipynb:
        warning: true
        error: true
        code-annotation: below
jupyter: julia-1.9
format-links: []
---

::: {.content-visible when-format="ipynb"}
**Name**:

**ID**:
:::

::: {.callout-important icon=false}
### Due Date

Friday, 10/06/23, 9:00pm
:::

::: {.content-visible when-format="html"}

:::{.callout-caution}

If you are enrolled in the course, make sure that you use the GitHub Classroom link provided in Ed Discussion, or you may not be able to get help if you run into problems.

Otherwise, you can [find the Github repository here]({{< var github_org.repo >}}/hw03).

:::

:::

## Overview

### Instructions

This assignment asks you to conduct a Monte Carlo analysis of levee reliability in the face of uncertain changes to local sea levels. You will propagate uncertainty in equilibrium climate sensitivity through the energy balance model to obtain a distribution of temperatures, which will then drive a model of sea-level rise. You will finally use this distribution to assess the probability that a planned levee will achieve its desired reliability standard.

### Load Environment

The following code loads the environment and makes sure all needed packages are installed. This should be at the start of most Julia scripts.

```{julia}
#| output: false
import Pkg
Pkg.activate(@__DIR__)
Pkg.instantiate()
```

```{julia}
using Random
using Plots
using LaTeXStrings
using Distributions
using CSV
using DataFrames
```

## Problems (Total: 40 Points)


::: {.cell .markdown}

### Problem 1 (12 points)

Recall from class that the simple energy balance model (EBM) of planetary energy balance links changes in radiative forcing ($F$) to global mean temperature ($T$) changes through the discretized equation
$$T_{i+1} = T_{i} + \frac{F_i - \lambda T_i}{cd} \times \Delta t,$$
where $i$ is the current time step, $c = 4.184 \times 10^6$ J/K/m^2^ is the heat capacity of water per unit area, $d$ is the (uncertain) depth of the mixing layer, $\Delta t$ is the annual time step in seconds and $\lambda = F_{\text{2xCO}_2}/S$ is the climate feedback parameter in W/m^2^/$^\circ$ C, where $S$ is the equilibrium climate sensitivity (the uncertain equilibrium temperature change resulting from a doubling of atmospheric CO~2~). Finally, while total radiative forcing can be the result of non-aerosol and aerosol effects, we do not know the relative intensity of aerosol forcing, so we represent this with an uncertain aerosol scaling factor $\alpha$.

We can implement this model with the following Julia function. We will assume an ocean mixing depth $d = 100$ m and an aerosol scaling factor $\alpha = 1.3$ so we can focus on the uncertainty in $S$. 

The last technical concern is that "global mean temperature" does not make sense in absolute terms as a marker of climate change. Instead, we typically refer to temperature changes relative to some historical pre-industrial baseline. In this case, we will use the period from 1880-1900, though this choice can vary.

:::

```{julia}
# we need to split up the aerosol and non-aerosol forcings when we call the function
function energy_balance_model(S, forcing_aerosol, forcing_non_aerosol)
    d = 100 # ocean mixing depth [m]
    α = 1.3 # aerosol scaling factor
    F2xCO₂ = 4.0 # radiative forcing [W/m²] for a doubling of CO₂
    λ = F2xCO₂/S
    
    c = 4.184e6 # heat capacity/area [J/K/m²]
    C = c*d # heat capacity of mixed layer (per area)

    F = forcing_non_aerosol + α*forcing_aerosol # radiative forcing

    Δt = 31558152.0 # annual timestep [s]
    
    T = zero(F)
    for i in 1:length(F)-1
        T[i+1] = T[i] + (F[i] - λ*T[i])/C * Δt
    end
    # return temperature anomaly relative to 1880-1900 baseline
    return T .- mean(T[1:21]) 
end
```

Finally, we need to load some radiative forcing data. We will use the radiative forcing scenario RCP 8.5. We can load this data, which is in a `.csv` (comma-delimited) file, into a `DataFrame`, which is a tabular data structure. Rows and columns in a `DataFrame` can be accessed using their numerical index (like a matrix), but columns also have names; you can access a particular column in a dataframe `df` by name using `df.colname` or `df[:, "colname"]`.

Of note: this data set goes from 1750--2500, so you will need to take care to make sure you are using the right years at each step. For example, here we will constrain the data to 1880--2100, which is the period we are interested in.

```{julia}
# The CSV is read into a DataFrame object, and we specify that it is comma delimited
forcings_all_85 = CSV.read("data/ERF_ssp585_1750-2500.csv", DataFrame, delim=",")

# get the years corresponding to the forcings
t = Int64.(forcings_all_85[!,"year"]) # Ensure that years are interpreted as integers
# find the indices of the years 1880 and 2100
# we can do this with the indexin function
time_bounds = indexin([1880, 2100], t)
years = time_bounds[1]:time_bounds[2] # create range of years

# Separate out the individual components
forcing_co2_85 = forcings_all_85[years,"co2"]
# Get total aerosol and non-aerosol forcings
forcing_aerosol_rad_85 = forcings_all_85[years,"aerosol-radiation_interactions"]
forcing_aerosol_cloud_85 = forcings_all_85[years,"aerosol-cloud_interactions"]
forcing_aerosol_85 = forcing_aerosol_rad_85 + forcing_aerosol_cloud_85 # aerosol forcings
forcing_total_85 = forcings_all_85[years,"total"] 
forcing_non_aerosol_85 = forcing_total_85 - forcing_aerosol_85 # non-aerosol forcings

```

For this assignment, you can use the `forcing_aerosol_85` and `forcing_non_aerosol_85` vectors as is to correspond to the relevant forcings. You will need to use the vector `t` to find the appropriate years for analysis.

::: {.cell .markdown}

#### Problem 1.1 (3 points)

Assume that $S$ is distributed according to $\text{LogNormal}(\log(3.2), \log{2}/3)$ (as in class). Draw 10,000 samples from this distribution and make a histogram.

:::

::: {.cell .markdown}

#### Problem 1.2 (5 points)

Use the EBM to propagate your samples of $S$ to a distribution of global mean temperature. Plot the median and 90% predictive distribution (between the .05 and .95 quantiles) from 1880-2100.
:::

::: {.cell .markdown}
#### Problem 1.3 (4 points)

Make a histogram of global mean temperature projections in 2100. If you compare this distribution to the distribution of $S$ from Problem 1.1, what do you observe?

:::

::: {.cell .markdown}
### Problem 2 (15 points)

Changes to global temperatures cause changes in global sea levels through several mechanisms, including thermal expansion (the change in ocean volume due to increased heat content) and melting land-based ice. One simple way to represent this link is through the following model, proposed by [Rahmstorf (2007)](https://doi.org/10.1126/science.1135456). 

$$\frac{dH}{dt} = a(T-T_0),$$

where $H$ is the global mean sea level in mm, $T$ is global mean temperature, $T_0$ is an equilibrium temperature (where there is no change in sea levels), and $a$ is a proportionality constant. This model can be discretized to give
$$H_{i+1} - H_i = a (T_i - T_0).$$

Note that, like with global mean temperature, the notion of "global mean sea level" does not make sense in absolute terms (were sea levels ever at "zero"?).  Instead, we want to normalize this relative to some historical baseline. In this case (with a view towards Problem 3), we will compute our sea levels relative to the 2010 sea level. Note that in addition to the model parameters, we also need an initial sea-level parameter $H_0$ which will give us the right anomaly level.

The best estimates for these parameters are:

- $a = 1.86$;
- $H_0 = -223$;
- $T_0 = -0.62$
:::

::: {.cell .markdown}
#### Problem 2.1 (5 points)

Write a function `sea_level_model()` to implement the mathematical sea-level rise model described above. It should take in needed parameters and a vector of temperatures and return a vector of sea levels. To test your function, use the provided temperature series `historical_temps` (read in below) to compute the global mean sea level anomaly in 2022 (the last year of the dataset) with the parameter values above; you should get a value of approximately 43mm.

:::

```{julia}
historical_temp_data = CSV.read("data/HadCRUT.5.0.1.0.analysis.summary_series.global.annual.csv", DataFrame, delim=",")
# column 2 is the temperature anomaly, column 1 is the year
temp_bds = indexin([1880, 1900], historical_temp_data[!, 1]) # find the index of 2010 for normalization
historical_temp_data[:, 2] .-= mean(historical_temp_data[temp_bds[1]:temp_bds[2], 2])
historical_temps = historical_temp_data[temp_bds[1]:end, 2]
```


::: {.cell .markdown}
#### Problem 2.2 (5 points)

Evaluate `sea_level_model()` using the projected temperature ensemble from Problem 1. Plot the 90% projection interval of the sea levels.
:::

::: {.cell .markdown}
#### Problem 2.3 (5 points)

Make a histogram of the sea-level anomaly in 2100. What can you observe about how the ECS uncertainty has impacted sea-level uncertainty under this radiative forcing scenario? What might the implications be of only using the best-estimate ECS value?

:::

::: {.cell .markdown}
### Problem 3 (13 points)

You've been asked to consult on a levee reliability analysis. For context, levees in the United States are supposed to only fail once in 100 years, or, in other words, to have at most a 1% chance of failure in a given year. We will assume for this problem that the only way in which a levee fails is by being overtopped (note: this is unrealistic).

We can assess the probability of levee overtopping by comparing its height to a distribution of extreme sea levels. A common approach is to look at the distribution of the highest sea level each year. These extreme sea levels can be obtained by combining the absolute sea level (we will use our distribution of global sea levels for this), the rate of subsidence (how much the ground sinks), and the distribution of storm tides (the highest tide level, which is often the result of storm surges combining with high tide). 

Assume for this problem that: 

1. the annual rate of subsidence $\nu$ is 1.2mm/yr;
2. the distribution of annual storm tide maxima, above the mean sea level, is (and is expected to continue to be) given by a $\text{GeneralizedExtremeValue}(900, 25, 0.3)$ distribution, which looks like this:

:::

```{julia}
tide_distribution = GeneralizedExtremeValue(900, 25, 0.3)
    histogram(rand(tide_distribution, 10000), xlabel="Storm Tide Height (mm)", ylabel="Count", legend=:false)
```

Feel free to just sample from `tide_distribution` in your solution below.

::: {.cell .markdown}
#### Problem 3.1 (2 points)

How would you use your sea-level simulations and the above information to compute a distribution of extreme sea levels in 2100 relative to 2010 mean sea level? Write down the approach in clear steps, with equations as needed.
:::

::: {.cell .markdown}
#### Problem 3.2 (3 points)

Follow the steps above and produce a histogram of the extreme sea levels in 2100 relative to 2010.
:::

::: {.cell .markdown}
#### Problem 3.2 (3 points)

Follow the steps above and produce a histogram of the extreme sea levels in 2100 relative to 2010.
:::

::: {.cell .markdown}
#### Problem 3.4 (3 points)

Based on your analysis, would you recommend that the levee be heightened again in the future, and if so, how high? What other information might you need, if any, to make your recommendation?
:::

::: {.cell .markdown}
## References

List any external references consulted, including classmates.
:::
